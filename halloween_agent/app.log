2024-10-26 12:29:10,187 - main - INFO - Serving root endpoint
2024-10-26 12:29:15,383 - main - INFO - Starting new image processing request
2024-10-26 12:29:15,450 - main - INFO - Getting LLM analysis
2024-10-26 12:29:15,451 - core - INFO - Starting image summarization
2024-10-26 12:33:59,840 - core - ERROR - Error in LLM processing: peer closed connection without sending complete message body (incomplete chunked read)
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 116, in __iter__
    for part in self._httpcore_stream:
                ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 367, in __iter__
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 363, in __iter__
    for part in self._stream:
                ^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 349, in __iter__
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 341, in __iter__
    for chunk in self._connection._receive_response_body(**kwargs):
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 210, in _receive_response_body
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 220, in _receive_event
    with map_exceptions({h11.RemoteProtocolError: RemoteProtocolError}):
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 87, in _stream
    for line in r.iter_lines():
                ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_models.py", line 863, in iter_lines
    for text in self.iter_text():
                ^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_models.py", line 850, in iter_text
    for byte_content in self.iter_bytes():
                        ^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_models.py", line 831, in iter_bytes
    for raw_bytes in self.iter_raw():
                     ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_models.py", line 885, in iter_raw
    for raw_stream_bytes in self.stream:
                            ^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 127, in __iter__
    for chunk in self._stream:
                 ^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 115, in __iter__
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: peer closed connection without sending complete message body (incomplete chunked read)

2024-10-26 12:33:59,840 - core - ERROR - Error in LLM processing: Server disconnected without sending a response.
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 101, in handle_request
    return self._connection.handle_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 143, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 113, in handle_request
    ) = self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 186, in _receive_response_headers
    event = self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/http11.py", line 238, in _receive_event
    raise RemoteProtocolError(msg)
httpcore.RemoteProtocolError: Server disconnected without sending a response.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.RemoteProtocolError: Server disconnected without sending a response.

2024-10-26 12:33:59,840 - main - ERROR - LLM processing error: Error in LLM processing: peer closed connection without sending complete message body (incomplete chunked read)
2024-10-26 12:33:59,840 - main - ERROR - LLM processing error: Error in LLM processing: Server disconnected without sending a response.
2024-10-26 12:33:59,848 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,848 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,849 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,849 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,849 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,849 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,850 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,850 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,850 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,850 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,851 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,851 - main - INFO - Serving root endpoint
2024-10-26 12:33:59,852 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,853 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,853 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,853 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,853 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,854 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,854 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,854 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,855 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,855 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,855 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,855 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,856 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,856 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,856 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,856 - main - INFO - Starting new image processing request
2024-10-26 12:33:59,877 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,877 - core - INFO - Starting image summarization
2024-10-26 12:33:59,888 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,888 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,889 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,889 - core - INFO - Starting image summarization
2024-10-26 12:33:59,901 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,902 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,902 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,902 - core - INFO - Starting image summarization
2024-10-26 12:33:59,912 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,912 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,913 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,913 - core - INFO - Starting image summarization
2024-10-26 12:33:59,922 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,922 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,922 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,923 - core - INFO - Starting image summarization
2024-10-26 12:33:59,931 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,931 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,932 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,932 - core - INFO - Starting image summarization
2024-10-26 12:33:59,941 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,941 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,941 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,941 - core - INFO - Starting image summarization
2024-10-26 12:33:59,951 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,951 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,952 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,952 - core - INFO - Starting image summarization
2024-10-26 12:33:59,960 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,960 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,961 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,961 - core - INFO - Starting image summarization
2024-10-26 12:33:59,971 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,971 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,972 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,972 - core - INFO - Starting image summarization
2024-10-26 12:33:59,983 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,983 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,984 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,984 - core - INFO - Starting image summarization
2024-10-26 12:33:59,992 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:33:59,992 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:33:59,993 - main - INFO - Getting LLM analysis
2024-10-26 12:33:59,993 - core - INFO - Starting image summarization
2024-10-26 12:34:00,001 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,001 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,001 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,002 - core - INFO - Starting image summarization
2024-10-26 12:34:00,010 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,010 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,010 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,010 - core - INFO - Starting image summarization
2024-10-26 12:34:00,018 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,018 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,018 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,018 - core - INFO - Starting image summarization
2024-10-26 12:34:00,026 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,026 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,027 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,027 - core - INFO - Starting image summarization
2024-10-26 12:34:00,035 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,035 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,035 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,035 - core - INFO - Starting image summarization
2024-10-26 12:34:00,043 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,043 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,044 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,044 - core - INFO - Starting image summarization
2024-10-26 12:34:00,053 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,053 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,054 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,054 - core - INFO - Starting image summarization
2024-10-26 12:34:00,063 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,063 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,063 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,063 - core - INFO - Starting image summarization
2024-10-26 12:34:00,071 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,071 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,071 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,071 - core - INFO - Starting image summarization
2024-10-26 12:34:00,080 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,080 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:34:00,081 - main - INFO - Getting LLM analysis
2024-10-26 12:34:00,081 - core - INFO - Starting image summarization
2024-10-26 12:34:00,089 - core - ERROR - Error in LLM processing: [Errno 111] Connection refused
Traceback (most recent call last):
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 72, in map_httpcore_exceptions
    yield
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 236, in handle_request
    resp = self._pool.handle_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 216, in handle_request
    raise exc from None
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py", line 196, in handle_request
    response = connection.handle_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 99, in handle_request
    raise exc
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 76, in handle_request
    stream = self._connect(request)
             ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_sync/connection.py", line 122, in _connect
    stream = self._network_backend.connect_tcp(**kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_backends/sync.py", line 205, in connect_tcp
    with map_exceptions(exc_map):
         ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpcore/_exceptions.py", line 14, in map_exceptions
    raise to_exc(exc) from exc
httpcore.ConnectError: [Errno 111] Connection refused

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/home/garlan/git/agents/agent_super_repo/halloween_agent/core.py", line 134, in summarize_image
    response = llm.invoke([message])
               ^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 286, in invoke
    self.generate_prompt(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 786, in generate_prompt
    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 643, in generate
    raise e
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 633, in generate
    self._generate_with_cache(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_core/language_models/chat_models.py", line 851, in _generate_with_cache
    result = self._generate(
             ^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 644, in _generate
    final_chunk = self._chat_stream_with_aggregation(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 545, in _chat_stream_with_aggregation
    for stream_resp in self._create_chat_stream(messages, stop, **kwargs):
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/langchain_ollama/chat_models.py", line 527, in _create_chat_stream
    yield from self._client.chat(
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/ollama/_client.py", line 80, in _stream
    with self._client.stream(method, url, **kwargs) as r:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 137, in __enter__
    return next(self.gen)
           ^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 880, in stream
    response = self.send(
               ^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 926, in send
    response = self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 954, in _send_handling_auth
    response = self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 991, in _send_handling_redirects
    response = self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_client.py", line 1027, in _send_single_request
    response = transport.handle_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 235, in handle_request
    with map_httpcore_exceptions():
         ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/contextlib.py", line 158, in __exit__
    self.gen.throw(value)
  File "/home/garlan/miniconda3/envs/agents/lib/python3.12/site-packages/httpx/_transports/default.py", line 89, in map_httpcore_exceptions
    raise mapped_exc(message) from exc
httpx.ConnectError: [Errno 111] Connection refused

2024-10-26 12:34:00,089 - main - ERROR - LLM processing error: Error in LLM processing: [Errno 111] Connection refused
2024-10-26 12:35:10,424 - main - INFO - Starting new image processing request
2024-10-26 12:35:10,520 - main - INFO - Getting LLM analysis
2024-10-26 12:35:10,520 - core - INFO - Starting image summarization
2024-10-26 12:35:12,039 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:14,760 - core - INFO - Successfully received LLM response
2024-10-26 12:35:14,760 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:15,381 - main - INFO - Starting new image processing request
2024-10-26 12:35:15,422 - main - INFO - Getting LLM analysis
2024-10-26 12:35:15,423 - core - INFO - Starting image summarization
2024-10-26 12:35:15,712 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:17,755 - core - INFO - Successfully received LLM response
2024-10-26 12:35:17,755 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:20,395 - main - INFO - Starting new image processing request
2024-10-26 12:35:20,426 - main - INFO - Getting LLM analysis
2024-10-26 12:35:20,426 - core - INFO - Starting image summarization
2024-10-26 12:35:20,669 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:22,983 - core - INFO - Successfully received LLM response
2024-10-26 12:35:22,983 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:25,387 - main - INFO - Starting new image processing request
2024-10-26 12:35:25,410 - main - INFO - Getting LLM analysis
2024-10-26 12:35:25,411 - core - INFO - Starting image summarization
2024-10-26 12:35:25,695 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:27,225 - core - INFO - Successfully received LLM response
2024-10-26 12:35:27,225 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:30,390 - main - INFO - Starting new image processing request
2024-10-26 12:35:30,419 - main - INFO - Getting LLM analysis
2024-10-26 12:35:30,419 - core - INFO - Starting image summarization
2024-10-26 12:35:30,704 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:33,380 - core - INFO - Successfully received LLM response
2024-10-26 12:35:33,380 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:35,395 - main - INFO - Starting new image processing request
2024-10-26 12:35:35,418 - main - INFO - Getting LLM analysis
2024-10-26 12:35:35,418 - core - INFO - Starting image summarization
2024-10-26 12:35:35,658 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:37,938 - core - INFO - Successfully received LLM response
2024-10-26 12:35:37,939 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:40,379 - main - INFO - Starting new image processing request
2024-10-26 12:35:40,410 - main - INFO - Getting LLM analysis
2024-10-26 12:35:40,410 - core - INFO - Starting image summarization
2024-10-26 12:35:40,696 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:43,283 - core - INFO - Successfully received LLM response
2024-10-26 12:35:43,283 - main - INFO - Successfully processed image and generated response
2024-10-26 12:35:45,414 - main - INFO - Starting new image processing request
2024-10-26 12:35:45,466 - main - INFO - Getting LLM analysis
2024-10-26 12:35:45,467 - core - INFO - Starting image summarization
2024-10-26 12:35:45,710 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/chat "HTTP/1.1 200 OK"
2024-10-26 12:35:48,060 - core - INFO - Successfully received LLM response
2024-10-26 12:35:48,063 - main - INFO - Successfully processed image and generated response
